{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "import datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This is a modified version of https://github.com/serega/gaoya/blob/master/py-gaoya/examples/deduplication_scholarly_articles_gaoya.ipynb, which benchmarks the algorithm on \n",
    "the `pinecone/core-2020-05-10-deduplication` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/chenghao/.cache/huggingface/datasets/pinecone___json/pinecone--core-2020-05-10-deduplication-dbaaf752a12c0b16/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "Loading cached processed dataset at /Users/chenghao/.cache/huggingface/datasets/pinecone___json/pinecone--core-2020-05-10-deduplication-dbaaf752a12c0b16/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-3f09ce0efdc0f6fc.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189d83f55f0f4aad9cb9d1035d24fd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the script\n",
    "\n",
    "ds = datasets.load_dataset(\"pinecone/core-2020-05-10-deduplication\", split=\"train\")\n",
    "ds = ds.map(lambda x: {\"text\": (x[\"processed_title\"] + \" \" + x[\"processed_abstract\"]).lower()})\n",
    "ds.save_to_disk(\"temp_inp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_from_disk(\"temp_inp\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/chenghao/Downloads/text-dedup/benchmarks/temp_inp/cache-5249773913bfa903.arrow\n"
     ]
    }
   ],
   "source": [
    "truth = ds.map(lambda x, id: {\"core_id\": x[\"core_id\"], \"id\": id, \"duplicates\": x[\"labelled_duplicates\"]}, remove_columns=ds.column_names, with_indices=True)\n",
    "id2core_id = {x[\"id\"]: int(x[\"core_id\"]) for x in truth}\n",
    "labels = {int(x[\"core_id\"]): set(map(int, x[\"duplicates\"])) if x[\"duplicates\"] else set() for x in truth}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MinHash"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no character shingle tokenizer in the script, you can either modify the code or use an n-gram tokenizer. For simplicity, we use bigrams in this example. Other parameters are the same as the original script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!python -m text_dedup.minhash --path ./temp_inp --local --column text --num_perm 200 --ngram 2 --threshold 0.5 --output temp --split train --debug --b 50 --r 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Correct': 92389,\n",
       " 'Incorrect': 7611,\n",
       " 'Accuracy': 0.9239,\n",
       " 'Recall': 0.9651,\n",
       " 'Precision': 0.4432}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"temp/uf.pkl\", \"rb\") as f:\n",
    "    uf = pickle.load(f)\n",
    "\n",
    "id2cluster = defaultdict(set)\n",
    "for id, cluster in uf.parent.items():\n",
    "    id2cluster[cluster].add(id)\n",
    "\n",
    "predictions = {id2core_id[x[\"id\"]]: set([id2core_id[neighbor] for neighbor in id2cluster[uf.find(x[\"id\"])] if neighbor != x[\"id\"]]) for x in truth}\n",
    "df = pd.Series(labels).to_frame(\"duplicates\").reset_index().merge(pd.Series(predictions).to_frame(\"predictions\").reset_index(), on=\"index\")\n",
    "\n",
    "df['Correct'] = df.apply(lambda row: set(row['duplicates']) == set(row['predictions']), axis=1).astype(int)\n",
    "prediction_summary = { 'Correct' : df['Correct'].sum(), 'Incorrect' : df.shape[0] - df['Correct'].sum() }\n",
    "prediction_summary['Accuracy'] = round(prediction_summary['Correct'] / df.shape[0], 4)\n",
    "\n",
    "def _recall(row):\n",
    "    labelled_dups = set(row['duplicates'])\n",
    "    if len(labelled_dups) == 0:\n",
    "        return 1\n",
    "    dups = set(row['predictions'])\n",
    "    return len(dups & labelled_dups) / len(labelled_dups)\n",
    "recalls = df.apply(lambda row: _recall(row), axis=1)\n",
    "prediction_summary['Recall'] = round(recalls.mean(), 4)\n",
    "\n",
    "def _precision(row):\n",
    "    labelled_dups = set(row['duplicates'])\n",
    "    dups = set(row['predictions'])    \n",
    "    if len(dups) == 0:\n",
    "        return 0\n",
    "\n",
    "    return len(dups & labelled_dups) / len(dups)\n",
    "precisions = df.apply(lambda row: _precision(row), axis=1)\n",
    "prediction_summary['Precision'] = round(precisions.mean(), 4)\n",
    "\n",
    "prediction_summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SimHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!python -m text_dedup.simhash --path ./temp_inp --local --column text --output temp_simhash --split train --debug \\\n",
    "    --bit_diff 6 \\\n",
    "    --num_bucket 7 \\\n",
    "    --ngram 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Correct': 82075,\n",
       " 'Incorrect': 17925,\n",
       " 'Accuracy': 0.8208,\n",
       " 'Recall': 0.8413,\n",
       " 'Precision': 0.3544}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"temp_simhash/uf.pkl\", \"rb\") as f:\n",
    "    uf = pickle.load(f)\n",
    "\n",
    "id2cluster = defaultdict(set)\n",
    "for id, cluster in uf.parent.items():\n",
    "    id2cluster[cluster].add(id)\n",
    "\n",
    "predictions = {id2core_id[x[\"id\"]]: set([id2core_id[neighbor] for neighbor in id2cluster[uf.find(x[\"id\"])] if neighbor != x[\"id\"]]) for x in truth}\n",
    "df = pd.Series(labels).to_frame(\"duplicates\").reset_index().merge(pd.Series(predictions).to_frame(\"predictions\").reset_index(), on=\"index\")\n",
    "\n",
    "df['Correct'] = df.apply(lambda row: set(row['duplicates']) == set(row['predictions']), axis=1).astype(int)\n",
    "prediction_summary = { 'Correct' : df['Correct'].sum(), 'Incorrect' : df.shape[0] - df['Correct'].sum() }\n",
    "prediction_summary['Accuracy'] = round(prediction_summary['Correct'] / df.shape[0], 4)\n",
    "\n",
    "def _recall(row):\n",
    "    labelled_dups = set(row['duplicates'])\n",
    "    if len(labelled_dups) == 0:\n",
    "        return 1\n",
    "    dups = set(row['predictions'])\n",
    "    return len(dups & labelled_dups) / len(labelled_dups)\n",
    "recalls = df.apply(lambda row: _recall(row), axis=1)\n",
    "prediction_summary['Recall'] = round(recalls.mean(), 4)\n",
    "\n",
    "def _precision(row):\n",
    "    labelled_dups = set(row['duplicates'])\n",
    "    dups = set(row['predictions'])    \n",
    "    if len(dups) == 0:\n",
    "        return 0\n",
    "\n",
    "    return len(dups & labelled_dups) / len(dups)\n",
    "precisions = df.apply(lambda row: _precision(row), axis=1)\n",
    "prediction_summary['Precision'] = round(precisions.mean(), 4)\n",
    "\n",
    "prediction_summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Deduplication of Scholarly Documents using Locality Sensitive Hashing and Word Embeddings](https://aclanthology.org/2020.lrec-1.113) (Gyawali et al., LREC 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9011, Recall: 0.6959, F1: 0.7853\n",
      "Precision: 0.7776, Recall: 0.9329, F1: 0.8482\n",
      "Macro Average F1: 0.8168, Accuracy: 0.8207\n"
     ]
    }
   ],
   "source": [
    "def classify_in_paper(record):\n",
    "    duplicates = set(record['duplicates'])\n",
    "    predictions = set(record['predictions'])\n",
    "\n",
    "    if len(predictions) == 0 and len(duplicates) > 0:\n",
    "        return 'FN'\n",
    "\n",
    "    if duplicates.issubset(predictions) and len(predictions) > 0 and len(duplicates) > 0:\n",
    "        return 'TP'\n",
    "    \n",
    "    if len(duplicates) == 0 and len(predictions) == 0:\n",
    "        return 'TN'\n",
    "    \n",
    "    if len(predictions) > 0:\n",
    "        if len(duplicates) == 0 or not duplicates.issubset(predictions):\n",
    "            return 'FP'\n",
    "    \n",
    "    raise ValueError(f'This should not happen {duplicates} {predictions} {len(duplicates)=} {len(predictions)=}')\n",
    "\n",
    "def inverse(label):\n",
    "    if label == 'TP':\n",
    "        return 'TN'\n",
    "    if label == 'FN':\n",
    "        return 'FP'\n",
    "    if label == 'FP':\n",
    "        return 'FN'\n",
    "    if label == 'TN':\n",
    "        return 'TP'\n",
    "\n",
    "df['Class'] = df.apply(lambda row: classify_in_paper(row), axis=1)\n",
    "df['Class_'] = df.apply(lambda row: inverse(row['Class']), axis=1)\n",
    "\n",
    "f1s = []\n",
    "for col in ['Class', 'Class_']:\n",
    "    label_counts = df[col].value_counts()\n",
    "    precision = label_counts['TP'] / (label_counts['TP'] + label_counts['FP'])\n",
    "    recall = label_counts['TP'] / (label_counts['TP'] + label_counts['FN'])\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')\n",
    "    f1s.append(f1)\n",
    "print(f'Macro Average F1: {sum(f1s) / len(f1s):.4f}, Accuracy: {df[\"Correct\"].mean():.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers seem too good to be true compared with what we see in the paper. Let's double check their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65b4f6226d24e7fac0db5f3a8270431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8302, Recall: 0.5521, F1: 0.6632\n",
      "Precision: 0.7098, Recall: 0.9065, F1: 0.7962\n",
      "Macro Average F1: 0.7297, Accuracy: 0.7456\n"
     ]
    }
   ],
   "source": [
    "title2core_ids = defaultdict(set)\n",
    "for record in ds:\n",
    "    title = record['processed_title']\n",
    "    core_id = int(record['core_id'])\n",
    "    title2core_ids[title].add(core_id)\n",
    "\n",
    "matches = ds.map(lambda row: {'matches': set(x for x in title2core_ids[row[\"processed_title\"]] if x != int(row[\"core_id\"]))})\n",
    "matches = {int(x[\"core_id\"]): x[\"matches\"] for x in matches}\n",
    "\n",
    "ddf = pd.Series(matches).to_frame(\"predictions\").reset_index().merge(df.drop(\"predictions\", axis=1), on=\"index\")\n",
    "ddf[\"Correct\"] = ddf.apply(lambda row: set(row['duplicates']) == set(row['predictions']), axis=1).astype(int)\n",
    "ddf['Class'] = ddf.apply(lambda row: classify_in_paper(row), axis=1)\n",
    "ddf['Class_'] = ddf.apply(lambda row: inverse(row['Class']), axis=1)\n",
    "\n",
    "f1s = []\n",
    "for col in ['Class', 'Class_']:\n",
    "    label_counts = ddf[col].value_counts()\n",
    "    precision = label_counts['TP'] / (label_counts['TP'] + label_counts['FP'])\n",
    "    recall = label_counts['TP'] / (label_counts['TP'] + label_counts['FN'])\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')\n",
    "    f1s.append(f1)\n",
    "print(f'Macro Average F1: {sum(f1s) / len(f1s):.4f}, Accuracy: {ddf[\"Correct\"].mean():.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is strange: precisions and accuracy are the same, but not the recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!rm -r temp_inp temp* ../temp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-dedup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34b527130893b47044197df5fe15869983e660be4f2927608e2aeec6a74366e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
